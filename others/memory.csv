spark.memory.fraction,0.6,"Fraction of (heap space - 300MB) used for execution and storage. The lower this is, the more frequently spills and cached data eviction occur. The purpose of this config is to set aside memory for internal metadata, user data structures, and imprecise size estimation in the case of sparse, unusually large records. Leaving this at the default value is recommended. For more detail, including important information about correctly tuning JVM garbage collection when increasing this value, see this description.",6
spark.memory.storageFraction,0.5,"Amount of storage memory immune to eviction, expressed as a fraction of the size of the region set aside by spark.memory.fraction. The higher this is, the less working memory may be available to execution and tasks may spill to disk more often. Leaving this at the default value is recommended. For more detail, see this description.",6
spark.memory.offHeap.enabled,FALSE,"If true, Spark will attempt to use off-heap memory for certain operations. If off-heap memory use is enabled, then spark.memory.offHeap.size must be positive.",6
spark.memory.offHeap.size,0,"The absolute amount of memory in bytes which can be used for off-heap allocation. This setting has no impact on heap memory usage, so if your executors' total memory consumption must fit within some hard limit then be sure to shrink your JVM heap size accordingly. This must be set to a positive value when spark.memory.offHeap.enabled=true.",6
spark.memory.useLegacyMode,FALSE,"Whether to enable the legacy memory management mode used in Spark 1.5 and before. The legacy mode rigidly partitions the heap space into fixed-size regions, potentially leading to excessive spilling if the application was not tuned. The following deprecated memory fraction configurations are not read unless this is enabled: spark.shuffle.memoryFraction
spark.storage.memoryFraction
spark.storage.unrollFraction",6
spark.shuffle.memoryFraction,0.2,"(deprecated) This is read only if spark.memory.useLegacyMode is enabled. Fraction of Java heap to use for aggregation and cogroups during shuffles. At any given time, the collective size of all in-memory maps used for shuffles is bounded by this limit, beyond which the contents will begin to spill to disk. If spills are often, consider increasing this value at the expense of spark.storage.memoryFraction.",6
spark.storage.memoryFraction,0.6,"(deprecated) This is read only if spark.memory.useLegacyMode is enabled. Fraction of Java heap to use for Spark's memory cache. This should not be larger than the ""old"" generation of objects in the JVM, which by default is given 0.6 of the heap, but you can increase it if you configure your own old generation size.",6
spark.storage.unrollFraction,0.2,(deprecated) This is read only if spark.memory.useLegacyMode is enabled. Fraction of spark.storage.memoryFraction to use for unrolling blocks in memory. This is dynamically allocated by dropping existing blocks when there is not enough free storage space to unroll the new block in its entirety.,6
spark.storage.replication.proactive,FALSE,Enables proactive block replication for RDD blocks. Cached RDD block replicas lost due to executor failures are replenished if there are any existing available replicas. This tries to get the replication level of the block to the initial number.,6
spark.cleaner.periodicGC.interval,30min,"Controls how often to trigger a garbage collection.

This context cleaner triggers cleanups only when weak references are garbage collected. In long-running applications with large driver JVMs, where there is little memory pressure on the driver, this may happen very occasionally or not at all. Not cleaning at all may lead to executors running out of disk space after a while.",6
spark.cleaner.referenceTracking,TRUE,Enables or disables context cleaning.,6
spark.cleaner.referenceTracking.blocking,TRUE,"Controls whether the cleaning thread should block on cleanup tasks (other than shuffle, which is controlled byspark.cleaner.referenceTracking.blocking.shuffle Spark property).",6
spark.cleaner.referenceTracking.blocking.shuffle,FALSE,Controls whether the cleaning thread should block on shuffle cleanup tasks.,6
spark.cleaner.referenceTracking.cleanCheckpoints,FALSE,Controls whether to clean checkpoint files if the reference is out of scope.,6