spark.reducer.maxSizeInFlight,48m,"Maximum size of map outputs to fetch simultaneously from each reduce task, in MiB unless otherwise specified. Since each output requires us to create a buffer to receive it, this represents a fixed memory overhead per reduce task, so keep it small unless you have a large amount of memory.",3
spark.reducer.maxReqsInFlight,Int.MaxValue,"This configuration limits the number of remote requests to fetch blocks at any given point. When the number of hosts in the cluster increase, it might lead to very large number of in-bound connections to one or more nodes, causing the workers to fail under load. By allowing it to limit the number of fetch requests, this scenario can be mitigated.",3
spark.reducer.maxBlocksInFlightPerAddress,Int.MaxValue,"This configuration limits the number of remote blocks being fetched per reduce task from a given host port. When a large number of blocks are being requested from a given address in a single fetch or simultaneously, this could crash the serving executor or Node Manager. This is especially useful to reduce the load on the Node Manager when external shuffle is enabled. You can mitigate this issue by setting it to a lower value.",3
spark.maxRemoteBlockSizeFetchToMem,Long.MaxValue,"The remote block will be fetched to disk when size of the block is above this threshold in bytes. This is to avoid a giant request takes too much memory. We can enable this config by setting a specific value(e.g. 200m). Note this configuration will affect both shuffle fetch and block manager remote block fetch. For users who enabled external shuffle service, this feature can only be worked when external shuffle service is newer than Spark 2.2.",3
spark.shuffle.compress,TRUE,Whether to compress map output files. Generally a good idea. Compression will use spark.io.compression.codec.,3
spark.shuffle.file.buffer,32k,"Size of the in-memory buffer for each shuffle file output stream, in KiB unless otherwise specified. These buffers reduce the number of disk seeks and system calls made in creating intermediate shuffle files.",3
spark.shuffle.io.maxRetries,3,(Netty only) Fetches that fail due to IO-related exceptions are automatically retried if this is set to a non-zero value. This retry logic helps stabilize large shuffles in the face of long GC pauses or transient network connectivity issues.,3
spark.shuffle.io.numConnectionsPerPeer,1,"(Netty only) Connections between hosts are reused in order to reduce connection buildup for large clusters. For clusters with many hard disks and few hosts, this may result in insufficient concurrency to saturate all disks, and so users may consider increasing this value.",3
spark.shuffle.io.preferDirectBufs,TRUE,"(Netty only) Off-heap buffers are used to reduce garbage collection during shuffle and cache block transfer. For environments where off-heap memory is tightly limited, users may wish to turn this off to force all allocations from Netty to be on-heap.",3
spark.shuffle.io.retryWait,5s,"(Netty only) How long to wait between retries of fetches. The maximum delay caused by retrying is 15 seconds by default, calculated as maxRetries * retryWait.",3
spark.shuffle.service.enabled,FALSE,"Enables the external shuffle service. This service preserves the shuffle files written by executors so the executors can be safely removed. This must be enabled if spark.dynamicAllocation.enabled is ""true"". The external shuffle service must be set up in order to enable it. Seedynamic allocation configuration and setup documentation for more information.",3
spark.shuffle.service.port,7337,Port on which the external shuffle service will run.,3
spark.shuffle.service.index.cache.size,100m,Cache entries limited to the specified memory footprint in bytes.,3
spark.shuffle.maxChunksBeingTransferred,Long.MAX_VALUE,"The max number of chunks allowed to be transferred at the same time on shuffle service. Note that new incoming connections will be closed when the max number is hit. The client will retry according to the shuffle retry configs (see spark.shuffle.io.maxRetries andspark.shuffle.io.retryWait), if those limits are reached the task will fail with fetch failure.",3
spark.shuffle.sort.bypassMergeThreshold,200,"(Advanced) In the sort-based shuffle manager, avoid merge-sorting data if there is no map-side aggregation and there are at most this many reduce partitions.",3
spark.shuffle.spill.compress,TRUE,Whether to compress data spilled during shuffles. Compression will usespark.io.compression.codec.,3
spark.shuffle.accurateBlockThreshold,100 * 1024 * 1024,Threshold in bytes above which the size of shuffle blocks in HighlyCompressedMapStatus is accurately recorded. This helps to prevent OOM by avoiding underestimating shuffle block size when fetch shuffle blocks.,3
spark.shuffle.registration.timeout,5000,Timeout in milliseconds for registration to the external shuffle service.,3
spark.shuffle.registration.maxAttempts,3,"When we fail to register to the external shuffle service, we will retry for maxAttempts times.",3
spark.io.encryption.enabled,FALSE,Enable IO encryption. Currently supported by all modes except Mesos. It's recommended that RPC encryption be enabled when using this feature.,3
spark.io.encryption.keySizeBits,128,"IO encryption key size in bits. Supported values are 128, 192 and 256.",3
spark.io.encryption.keygen.algorithm,HmacSHA1,The algorithm to use when generating the IO encryption key. The supported algorithms are described in the KeyGenerator section of the Java Cryptography Architecture Standard Algorithm Name Documentation.,3